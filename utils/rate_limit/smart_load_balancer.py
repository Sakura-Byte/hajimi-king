"""
åŸºäºAPIé…é¢çš„æ™ºèƒ½è´Ÿè½½å‡è¡¡å™¨
ç»¼åˆç®¡ç†GitHub tokensã€proxieså’ŒGemini APIçš„æ™ºèƒ½åˆ†é…å’Œè´Ÿè½½å‡è¡¡
"""

import random
import time
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, field
from enum import Enum
from collections import defaultdict, deque
import statistics

from common.Logger import logger
from common.config import Config
from .quota_monitor import QuotaMonitor
from .token_manager import TokenManager


class ResourceType(Enum):
    """èµ„æºç±»å‹"""
    GITHUB_TOKEN = "github_token"
    PROXY = "proxy"
    GEMINI_KEY = "gemini_key"


@dataclass
class ResourceHealth:
    """èµ„æºå¥åº·çŠ¶æ€"""
    resource_id: str
    resource_type: ResourceType
    health_score: float = 1.0    # å¥åº·åº¦è¯„åˆ† 0-1
    availability: float = 1.0    # å¯ç”¨æ€§ 0-1
    response_time: float = 0.0   # å¹³å‡å“åº”æ—¶é—´
    error_rate: float = 0.0      # é”™è¯¯ç‡ 0-1
    load_factor: float = 0.0     # è´Ÿè½½å› å­ 0-1
    last_used: float = 0.0       # æœ€åä½¿ç”¨æ—¶é—´
    consecutive_errors: int = 0   # è¿ç»­é”™è¯¯æ¬¡æ•°
    recovery_time: float = 0.0   # æ¢å¤æ—¶é—´ä¼°ç®—
    
    @property
    def is_healthy(self) -> bool:
        return self.health_score > 0.3 and self.availability > 0.5
    
    @property
    def is_overloaded(self) -> bool:
        return self.load_factor > 0.8
    
    @property
    def needs_rest(self) -> bool:
        return self.consecutive_errors > 3 or self.error_rate > 0.3


@dataclass 
class LoadBalancingDecision:
    """è´Ÿè½½å‡è¡¡å†³ç­–"""
    resource_id: str
    resource_type: ResourceType
    confidence: float      # å†³ç­–ç½®ä¿¡åº¦ 0-1
    expected_latency: float # é¢„æœŸå»¶è¿Ÿ
    alternative_resources: List[str] = field(default_factory=list)
    decision_reason: str = ""


class PredictiveLoadBalancer:
    """é¢„æµ‹æ€§è´Ÿè½½å‡è¡¡å™¨"""
    
    def __init__(self, quota_monitor: QuotaMonitor, token_manager: TokenManager):
        self.quota_monitor = quota_monitor
        self.token_manager = token_manager
        
        # èµ„æºå¥åº·çŠ¶æ€è¿½è¸ª
        self.resource_health: Dict[str, ResourceHealth] = {}
        
        # å†å²æ€§èƒ½æ•°æ® (ç”¨äºé¢„æµ‹)
        self.performance_history: Dict[str, deque] = defaultdict(lambda: deque(maxlen=100))
        self.latency_history: Dict[str, deque] = defaultdict(lambda: deque(maxlen=50))
        
        # è´Ÿè½½å‡è¡¡ç­–ç•¥ (æœªä½¿ç”¨ï¼Œå·²ç§»é™¤)
        
        # é¢„æµ‹æ¨¡å‹å‚æ•°
        self.prediction_window = 300  # 5åˆ†é’Ÿé¢„æµ‹çª—å£
        self.load_smoothing_factor = 0.1  # è´Ÿè½½å¹³æ»‘å› å­
        
        # æ•…éšœè½¬ç§»é…ç½®
        self.failover_threshold = 0.2  # å¥åº·åº¦ä½äºæ­¤å€¼è§¦å‘æ•…éšœè½¬ç§»
        self.recovery_period = 300     # èµ„æºæ¢å¤è§‚å¯ŸæœŸ(ç§’)
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_decisions': 0,
            'failover_events': 0,
            'load_redistributions': 0,
            'prediction_accuracy': 0.0,
            'avg_response_time': defaultdict(float),
            'resource_utilization': defaultdict(float)
        }
        
        # åˆå§‹åŒ–èµ„æºå¥åº·çŠ¶æ€
        self._initialize_resource_health()
        
        logger.info("ğŸ¯ PredictiveLoadBalancer initialized")
    
    def _initialize_resource_health(self):
        """åˆå§‹åŒ–æ‰€æœ‰èµ„æºçš„å¥åº·çŠ¶æ€"""
        # GitHub tokens
        for token in self.quota_monitor.github_tokens:
            self.resource_health[token] = ResourceHealth(
                resource_id=token,
                resource_type=ResourceType.GITHUB_TOKEN
            )
        
        # Proxies
        for i, proxy in enumerate(Config.PROXY_LIST):
            proxy_id = f"proxy_{i}_{hash(proxy) % 1000}"
            self.resource_health[proxy_id] = ResourceHealth(
                resource_id=proxy_id,
                resource_type=ResourceType.PROXY
            )
        
        # Gemini (ç®€åŒ–ä¸ºå•ä¸€èµ„æº)
        self.resource_health["gemini_primary"] = ResourceHealth(
            resource_id="gemini_primary",
            resource_type=ResourceType.GEMINI_KEY
        )
    
    async def get_best_github_token(self, task_priority: int = 5, predicted_load: float = 1.0) -> Optional[LoadBalancingDecision]:
        """
        è·å–æœ€ä½³GitHub token
        
        Args:
            task_priority: ä»»åŠ¡ä¼˜å…ˆçº§
            predicted_load: é¢„æœŸè´Ÿè½½
        
        Returns:
            LoadBalancingDecision: è´Ÿè½½å‡è¡¡å†³ç­–
        """
        self.stats['total_decisions'] += 1
        
        # æ›´æ–°æ‰€æœ‰GitHub tokençš„å¥åº·çŠ¶æ€
        await self._update_github_token_health()
        
        # è·å–å€™é€‰token
        candidates = []
        for token in self.quota_monitor.github_tokens:
            health = self.resource_health.get(token)
            if not health or not health.is_healthy:
                continue
            
            # è®¡ç®—tokenå¾—åˆ†
            score = self._calculate_github_token_score(token, task_priority, predicted_load)
            candidates.append((score, token))
        
        if not candidates:
            # æ²¡æœ‰å¥åº·çš„tokenï¼Œå°è¯•æ•…éšœè½¬ç§»
            return await self._handle_github_token_failover(task_priority)
        
        # é€‰æ‹©æœ€ä½³token
        candidates.sort(reverse=True)
        best_score, best_token = candidates[0]
        
        # é¢„æµ‹å»¶è¿Ÿ
        predicted_latency = self._predict_token_latency(best_token, predicted_load)
        
        # æ„å»ºå†³ç­–
        decision = LoadBalancingDecision(
            resource_id=best_token,
            resource_type=ResourceType.GITHUB_TOKEN,
            confidence=min(1.0, best_score),
            expected_latency=predicted_latency,
            alternative_resources=[token for _, token in candidates[1:3]],  # å‰2ä¸ªå¤‡é€‰
            decision_reason=f"Best score: {best_score:.3f}, predicted latency: {predicted_latency:.2f}s"
        )
        
        # æ›´æ–°ä½¿ç”¨è®°å½•
        self.resource_health[best_token].last_used = time.time()
        self.resource_health[best_token].load_factor = min(1.0, self.resource_health[best_token].load_factor + predicted_load * 0.1)
        
        return decision
    
    async def get_best_proxy(self, task_context: str = "") -> Optional[LoadBalancingDecision]:
        """è·å–æœ€ä½³ä»£ç†"""
        if not Config.PROXY_LIST:
            return None
        
        await self._update_proxy_health()
        
        # è®¡ç®—ä»£ç†å¾—åˆ†
        candidates = []
        for proxy_id, health in self.resource_health.items():
            if health.resource_type != ResourceType.PROXY or not health.is_healthy:
                continue
            
            score = health.health_score * 0.6 + (1 - health.load_factor) * 0.4
            candidates.append((score, proxy_id))
        
        if not candidates:
            # éšæœºé€‰æ‹©ä¸€ä¸ªä»£ç†ä½œä¸ºfallback
            fallback_proxy = f"proxy_fallback_{random.randint(0, len(Config.PROXY_LIST)-1)}"
            return LoadBalancingDecision(
                resource_id=fallback_proxy,
                resource_type=ResourceType.PROXY,
                confidence=0.3,
                expected_latency=10.0,
                decision_reason="Fallback proxy due to no healthy proxies"
            )
        
        candidates.sort(reverse=True)
        best_score, best_proxy_id = candidates[0]
        
        decision = LoadBalancingDecision(
            resource_id=best_proxy_id,
            resource_type=ResourceType.PROXY,
            confidence=min(1.0, best_score),
            expected_latency=self.resource_health[best_proxy_id].response_time,
            alternative_resources=[proxy_id for _, proxy_id in candidates[1:2]],
            decision_reason=f"Best proxy score: {best_score:.3f}"
        )
        
        return decision
    
    def record_resource_performance(self, resource_id: str, success: bool, response_time: float, error_type: str = ""):
        """
        è®°å½•èµ„æºæ€§èƒ½æ•°æ®
        
        Args:
            resource_id: èµ„æºID
            success: æ˜¯å¦æˆåŠŸ
            response_time: å“åº”æ—¶é—´
            error_type: é”™è¯¯ç±»å‹
        """
        if resource_id not in self.resource_health:
            return
        
        health = self.resource_health[resource_id]
        current_time = time.time()
        
        # æ›´æ–°å“åº”æ—¶é—´
        self.latency_history[resource_id].append(response_time)
        if self.latency_history[resource_id]:
            health.response_time = statistics.mean(self.latency_history[resource_id])
        
        # æ›´æ–°æˆåŠŸ/å¤±è´¥è®°å½•
        self.performance_history[resource_id].append(1 if success else 0)
        
        if success:
            health.consecutive_errors = 0
            # é€æ¸æ¢å¤å¥åº·åº¦
            health.health_score = min(1.0, health.health_score + 0.02)
        else:
            health.consecutive_errors += 1
            # é™ä½å¥åº·åº¦
            penalty = 0.1 if error_type in ["timeout", "connection_error"] else 0.05
            health.health_score = max(0.0, health.health_score - penalty)
            
            # 429é”™è¯¯ç‰¹æ®Šå¤„ç†
            if "429" in error_type:
                health.health_score = max(0.0, health.health_score - 0.2)
                health.recovery_time = current_time + 300  # 5åˆ†é’Ÿæ¢å¤æœŸ
        
        # æ›´æ–°é”™è¯¯ç‡
        recent_performance = list(self.performance_history[resource_id])[-20:]  # æœ€è¿‘20æ¬¡
        if recent_performance:
            health.error_rate = 1.0 - (sum(recent_performance) / len(recent_performance))
        
        # æ›´æ–°å¯ç”¨æ€§
        if health.consecutive_errors > 5:
            health.availability = 0.0
        elif health.consecutive_errors > 2:
            health.availability = 0.5
        else:
            health.availability = 1.0
        
        # æ›´æ–°ç»Ÿè®¡
        resource_type = health.resource_type.value
        self.stats['avg_response_time'][resource_type] = (
            self.stats['avg_response_time'][resource_type] * 0.9 + response_time * 0.1
        )
    
    async def _update_github_token_health(self):
        """æ›´æ–°GitHub tokenå¥åº·çŠ¶æ€"""
        for token in self.quota_monitor.github_tokens:
            if token not in self.resource_health:
                continue
            
            health = self.resource_health[token]
            quota_status = self.quota_monitor.github_quota_status.get(token)
            
            if quota_status:
                # åŸºäºé…é¢çŠ¶æ€æ›´æ–°å¥åº·åº¦
                quota_health = quota_status.health_score
                
                # ç»¼åˆè€ƒè™‘é…é¢å¥åº·åº¦å’Œå†å²æ€§èƒ½
                health.health_score = quota_health * 0.7 + health.health_score * 0.3
                
                # åŸºäºå‰©ä½™é…é¢è®¡ç®—è´Ÿè½½å› å­
                health.load_factor = 1.0 - quota_status.remaining_ratio
                
                # å¦‚æœé…é¢è€—å°½ï¼Œè®¾ç½®æ¢å¤æ—¶é—´
                if quota_status.remaining <= 0:
                    health.recovery_time = quota_status.reset_time
                    health.availability = 0.0
    
    async def _update_proxy_health(self):
        """æ›´æ–°ä»£ç†å¥åº·çŠ¶æ€"""
        current_time = time.time()
        
        for proxy_id, health in self.resource_health.items():
            if health.resource_type != ResourceType.PROXY:
                continue
            
            # å¦‚æœé•¿æ—¶é—´æœªä½¿ç”¨ï¼Œé€æ¸é™ä½è´Ÿè½½å› å­
            if current_time - health.last_used > 300:  # 5åˆ†é’Ÿ
                health.load_factor = max(0.0, health.load_factor - 0.1)
            
            # å¦‚æœåœ¨æ¢å¤æœŸå†…ï¼Œæ£€æŸ¥æ˜¯å¦å¯ä»¥æ¢å¤
            if health.recovery_time > 0 and current_time >= health.recovery_time:
                health.recovery_time = 0
                health.consecutive_errors = 0
                health.health_score = 0.5  # é‡ç½®ä¸ºä¸­ç­‰å¥åº·åº¦
                logger.info(f"ğŸ”„ Proxy {proxy_id} recovered from failure")
    
    def _calculate_github_token_score(self, token: str, task_priority: int, predicted_load: float) -> float:
        """è®¡ç®—GitHub tokenå¾—åˆ†"""
        health = self.resource_health.get(token)
        quota_status = self.quota_monitor.github_quota_status.get(token)
        
        if not health or not quota_status:
            return 0.0
        
        # åŸºç¡€å¾—åˆ†ï¼šå¥åº·åº¦å’Œé…é¢çŠ¶æ€
        base_score = health.health_score * 0.5 + quota_status.health_score * 0.5
        
        # è´Ÿè½½å¹³è¡¡è°ƒæ•´
        load_penalty = health.load_factor * 0.3
        base_score -= load_penalty
        
        # ä¼˜å…ˆçº§è°ƒæ•´
        if task_priority <= 2:  # é«˜ä¼˜å…ˆçº§ä»»åŠ¡
            # é«˜ä¼˜å…ˆçº§ä»»åŠ¡æ›´åå¥½é«˜é…é¢token
            quota_bonus = quota_status.remaining_ratio * 0.2
            base_score += quota_bonus
        elif task_priority >= 7:  # ä½ä¼˜å…ˆçº§ä»»åŠ¡
            # ä½ä¼˜å…ˆçº§ä»»åŠ¡é¿å…ä½¿ç”¨é«˜é…é¢token
            if quota_status.remaining_ratio > 0.7:
                base_score -= 0.1
        
        # å“åº”æ—¶é—´è°ƒæ•´
        if health.response_time > 0:
            latency_penalty = min(0.2, health.response_time / 10)
            base_score -= latency_penalty
        
        # é¢„æœŸè´Ÿè½½è°ƒæ•´
        future_load = health.load_factor + predicted_load * 0.1
        if future_load > 0.8:
            base_score -= 0.3  # é¿å…è¿‡è½½
        
        return max(0.0, min(1.0, base_score))
    
    def _predict_token_latency(self, token: str, predicted_load: float) -> float:
        """é¢„æµ‹tokenå“åº”å»¶è¿Ÿ"""
        health = self.resource_health.get(token)
        if not health:
            return 5.0  # é»˜è®¤å»¶è¿Ÿ
        
        base_latency = health.response_time if health.response_time > 0 else 2.0
        
        # æ ¹æ®è´Ÿè½½è°ƒæ•´å»¶è¿Ÿ
        load_multiplier = 1.0 + health.load_factor * 0.5
        
        # æ ¹æ®å¥åº·åº¦è°ƒæ•´
        health_multiplier = 2.0 - health.health_score  # å¥åº·åº¦è¶Šä½å»¶è¿Ÿè¶Šé«˜
        
        predicted_latency = base_latency * load_multiplier * health_multiplier
        
        return min(30.0, predicted_latency)  # æœ€å¤§30ç§’å»¶è¿Ÿ
    
    async def _handle_github_token_failover(self, task_priority: int) -> Optional[LoadBalancingDecision]:
        """å¤„ç†GitHub tokenæ•…éšœè½¬ç§»"""
        self.stats['failover_events'] += 1
        
        # å¯»æ‰¾æ¢å¤ä¸­çš„token
        recovering_tokens = []
        current_time = time.time()
        
        for token in self.quota_monitor.github_tokens:
            health = self.resource_health.get(token)
            if not health:
                continue
            
            # æ£€æŸ¥æ˜¯å¦åœ¨æ¢å¤æœŸ
            if health.recovery_time > 0 and current_time >= health.recovery_time:
                recovering_tokens.append(token)
        
        if recovering_tokens:
            # é€‰æ‹©ä¸€ä¸ªæ¢å¤ä¸­çš„token
            best_token = min(recovering_tokens, key=lambda t: self.resource_health[t].consecutive_errors)
            
            return LoadBalancingDecision(
                resource_id=best_token,
                resource_type=ResourceType.GITHUB_TOKEN,
                confidence=0.3,
                expected_latency=10.0,
                decision_reason="Failover to recovering token"
            )
        
        # é€‰æ‹©æœ€ä¸åçš„token
        least_bad_token = min(
            self.quota_monitor.github_tokens,
            key=lambda t: self.resource_health.get(t, ResourceHealth("", ResourceType.GITHUB_TOKEN)).consecutive_errors
        )
        
        return LoadBalancingDecision(
            resource_id=least_bad_token,
            resource_type=ResourceType.GITHUB_TOKEN,
            confidence=0.1,
            expected_latency=15.0,
            decision_reason="Emergency fallback to least-bad token"
        )
    
    def rebalance_load(self) -> Dict[str, Any]:
        """æ‰§è¡Œè´Ÿè½½é‡æ–°å‡è¡¡"""
        self.stats['load_redistributions'] += 1
        
        rebalance_actions = []
        
        # GitHub tokenè´Ÿè½½å‡è¡¡
        github_actions = self._rebalance_github_tokens()
        rebalance_actions.extend(github_actions)
        
        # Proxyè´Ÿè½½å‡è¡¡
        proxy_actions = self._rebalance_proxies()
        rebalance_actions.extend(proxy_actions)
        
        logger.info(f"ğŸ”„ Load rebalancing completed with {len(rebalance_actions)} actions")
        
        return {
            'actions_taken': len(rebalance_actions),
            'actions_detail': rebalance_actions,
            'rebalance_timestamp': time.time()
        }
    
    def _rebalance_github_tokens(self) -> List[Dict]:
        """é‡æ–°å‡è¡¡GitHub tokenè´Ÿè½½"""
        actions = []
        
        # æ‰¾å‡ºè¿‡è½½å’Œç©ºé—²çš„token
        overloaded_tokens = []
        underutilized_tokens = []
        
        for token in self.quota_monitor.github_tokens:
            health = self.resource_health.get(token)
            if not health:
                continue
            
            if health.is_overloaded and health.is_healthy:
                overloaded_tokens.append(token)
            elif health.load_factor < 0.3 and health.is_healthy:
                underutilized_tokens.append(token)
        
        # æ‰§è¡Œè´Ÿè½½è½¬ç§»
        for overloaded_token in overloaded_tokens:
            if not underutilized_tokens:
                break
            
            target_token = underutilized_tokens.pop(0)
            
            # å‡å°‘è¿‡è½½tokençš„è´Ÿè½½
            self.resource_health[overloaded_token].load_factor *= 0.8
            # å¢åŠ ç›®æ ‡tokençš„è´Ÿè½½
            self.resource_health[target_token].load_factor += 0.2
            
            actions.append({
                'type': 'load_transfer',
                'from': overloaded_token[:10] + "...",
                'to': target_token[:10] + "...",
                'amount': 0.2
            })
        
        return actions
    
    def _rebalance_proxies(self) -> List[Dict]:
        """é‡æ–°å‡è¡¡ä»£ç†è´Ÿè½½"""
        actions = []
        
        proxy_healths = [
            (proxy_id, health) for proxy_id, health in self.resource_health.items()
            if health.resource_type == ResourceType.PROXY
        ]
        
        if len(proxy_healths) < 2:
            return actions
        
        # æŒ‰å¥åº·åº¦æ’åº
        proxy_healths.sort(key=lambda x: x[1].health_score, reverse=True)
        
        # å¦‚æœæœ€å¥½å’Œæœ€åçš„ä»£ç†å¥åº·åº¦å·®å¼‚å¾ˆå¤§ï¼Œå»ºè®®åˆ‡æ¢
        best_proxy = proxy_healths[0]
        worst_proxy = proxy_healths[-1]
        
        health_diff = best_proxy[1].health_score - worst_proxy[1].health_score
        
        if health_diff > 0.4:
            actions.append({
                'type': 'proxy_recommendation',
                'recommend': best_proxy[0],
                'avoid': worst_proxy[0],
                'reason': f'Health difference: {health_diff:.2f}'
            })
        
        return actions
    
    def get_load_balancer_stats(self) -> Dict:
        """è·å–è´Ÿè½½å‡è¡¡å™¨ç»Ÿè®¡ä¿¡æ¯"""
        resource_summary = defaultdict(lambda: {'count': 0, 'healthy': 0, 'avg_load': 0.0, 'avg_health': 0.0})
        
        for resource_id, health in self.resource_health.items():
            resource_type = health.resource_type.value
            resource_summary[resource_type]['count'] += 1
            
            if health.is_healthy:
                resource_summary[resource_type]['healthy'] += 1
            
            resource_summary[resource_type]['avg_load'] += health.load_factor
            resource_summary[resource_type]['avg_health'] += health.health_score
        
        # è®¡ç®—å¹³å‡å€¼
        for resource_type in resource_summary:
            count = resource_summary[resource_type]['count']
            if count > 0:
                resource_summary[resource_type]['avg_load'] /= count
                resource_summary[resource_type]['avg_health'] /= count
        
        return {
            'resource_summary': dict(resource_summary),
            'global_stats': self.stats.copy(),
            'health_distribution': {
                'healthy': sum(1 for h in self.resource_health.values() if h.is_healthy),
                'unhealthy': sum(1 for h in self.resource_health.values() if not h.is_healthy),
                'recovering': sum(1 for h in self.resource_health.values() if h.recovery_time > time.time()),
                'overloaded': sum(1 for h in self.resource_health.values() if h.is_overloaded)
            },
            'top_performers': self._get_top_performing_resources(),
            'bottlenecks': self._identify_bottlenecks()
        }
    
    def _get_top_performing_resources(self) -> Dict[str, List[str]]:
        """è·å–æ€§èƒ½æœ€ä½³çš„èµ„æº"""
        by_type = defaultdict(list)
        
        for resource_id, health in self.resource_health.items():
            by_type[health.resource_type.value].append((health.health_score, resource_id))
        
        top_performers = {}
        for resource_type, resources in by_type.items():
            resources.sort(reverse=True)
            top_performers[resource_type] = [resource_id for _, resource_id in resources[:3]]
        
        return top_performers
    
    def _identify_bottlenecks(self) -> List[Dict]:
        """è¯†åˆ«æ€§èƒ½ç“¶é¢ˆ"""
        bottlenecks = []
        
        for resource_id, health in self.resource_health.items():
            issues = []
            
            if health.health_score < 0.3:
                issues.append("low_health")
            if health.error_rate > 0.2:
                issues.append("high_error_rate")
            if health.response_time > 10:
                issues.append("high_latency")
            if health.is_overloaded:
                issues.append("overloaded")
            
            if issues:
                bottlenecks.append({
                    'resource_id': resource_id[:20] + "..." if len(resource_id) > 20 else resource_id,
                    'resource_type': health.resource_type.value,
                    'issues': issues,
                    'severity': len(issues) / 4.0
                })
        
        return sorted(bottlenecks, key=lambda x: x['severity'], reverse=True)[:5]