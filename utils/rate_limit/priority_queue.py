"""
APIé…é¢æ„ŸçŸ¥çš„ä¼˜å…ˆçº§é˜Ÿåˆ—ç³»ç»Ÿ
æ ¹æ®APIé…é¢çŠ¶æ€å’Œä»»åŠ¡ç‰¹æ€§åŠ¨æ€è®¡ç®—ä»»åŠ¡ä¼˜å…ˆçº§
"""

import heapq
import re
import time
from dataclasses import dataclass
from datetime import datetime
from enum import Enum
from typing import Any

from common.Logger import logger


class TaskPriority(Enum):
    """ä»»åŠ¡ä¼˜å…ˆçº§ç­‰çº§"""

    CRITICAL = 0  # ç´§æ€¥ä»»åŠ¡
    HIGH = 1  # é«˜ä¼˜å…ˆçº§
    MEDIUM = 5  # ä¸­ç­‰ä¼˜å…ˆçº§
    LOW = 7  # ä½ä¼˜å…ˆçº§
    BACKGROUND = 9  # åå°ä»»åŠ¡


@dataclass
class FileTaskInfo:
    """æ–‡ä»¶ä»»åŠ¡ä¿¡æ¯"""

    repo_name: str
    file_path: str
    file_size: int
    repo_stars: int
    repo_updated_at: str
    file_url: str
    content_preview: str | None = None

    @property
    def estimated_key_density(self) -> float:
        """ä¼°ç®—API keyå¯†åº¦"""
        if not self.content_preview:
            # åŸºäºæ–‡ä»¶æ‰©å±•åä¼°ç®—
            if self.file_path.endswith((".js", ".ts", ".py", ".env", ".config")):
                return 0.7
            if self.file_path.endswith((".json", ".yaml", ".yml")):
                return 0.8
            if self.file_path.endswith((".md", ".txt", ".rst")):
                return 0.2
            return 0.5

        # åŸºäºå†…å®¹åˆ†æ
        api_key_pattern = r"AIzaSy[A-Za-z0-9\-_]{33}"
        potential_keys = len(re.findall(api_key_pattern, self.content_preview))
        content_length = len(self.content_preview)

        if content_length == 0:
            return 0.0

        # å¯†åº¦ = æ½œåœ¨keyæ•°é‡ / å†…å®¹é•¿åº¦ * 1000 (æ ‡å‡†åŒ–)
        density = (potential_keys / content_length) * 1000
        return min(1.0, density)

    @property
    def repo_freshness_score(self) -> float:
        """ä»“åº“æ–°é²œåº¦è¯„åˆ†"""
        try:
            updated_dt = datetime.strptime(self.repo_updated_at, "%Y-%m-%dT%H:%M:%SZ")
            days_since_update = (datetime.utcnow() - updated_dt).days

            # è¶Šæ–°é²œåˆ†æ•°è¶Šé«˜
            if days_since_update <= 7:
                return 1.0
            if days_since_update <= 30:
                return 0.8
            if days_since_update <= 90:
                return 0.6
            if days_since_update <= 365:
                return 0.4
            return 0.2
        except (ValueError, TypeError, KeyError):
            return 0.5  # é»˜è®¤åˆ†æ•°

    @property
    def repo_popularity_score(self) -> float:
        """ä»“åº“æµè¡Œåº¦è¯„åˆ†"""
        if self.repo_stars >= 10000:
            return 1.0
        if self.repo_stars >= 1000:
            return 0.8
        if self.repo_stars >= 100:
            return 0.6
        if self.repo_stars >= 10:
            return 0.4
        return 0.2


@dataclass
class KeyValidationTaskInfo:
    """KeyéªŒè¯ä»»åŠ¡ä¿¡æ¯"""

    key: str
    repo_name: str
    file_path: str
    repo_stars: int
    key_source_context: str  # keyå‘¨å›´çš„ä¸Šä¸‹æ–‡

    @property
    def key_confidence_score(self) -> float:
        """Keyå¯ä¿¡åº¦è¯„åˆ†"""
        # åŸºäºä¸Šä¸‹æ–‡åˆ†ækeyçš„å¯ä¿¡åº¦
        context_lower = self.key_source_context.lower()

        # è´Ÿé¢æŒ‡æ ‡
        if any(
            keyword in context_lower for keyword in ["example", "sample", "demo", "test", "placeholder", "your_api_key"]
        ):
            return 0.1

        if "..." in self.key_source_context:
            return 0.2

        # æ­£é¢æŒ‡æ ‡
        confidence = 0.5  # åŸºç¡€åˆ†æ•°

        if any(keyword in context_lower for keyword in ["api_key", "google_api", "gemini", "generative"]):
            confidence += 0.3

        if re.search(r'["\']' + re.escape(self.key) + r'["\']', self.key_source_context):
            confidence += 0.2  # è¢«å¼•å·åŒ…å›´

        return min(1.0, confidence)


class PriorityCalculator:
    """ä¼˜å…ˆçº§è®¡ç®—å™¨"""

    def __init__(self):
        # æƒé‡é…ç½®
        self.weights = {
            "api_quota_efficiency": 0.35,  # APIé…é¢æ•ˆç‡
            "expected_success_rate": 0.25,  # é¢„æœŸæˆåŠŸç‡
            "repo_value": 0.20,  # ä»“åº“ä»·å€¼
            "task_urgency": 0.15,  # ä»»åŠ¡ç´§æ€¥åº¦
            "resource_cost": 0.05,  # èµ„æºæˆæœ¬
        }

    def calculate_file_task_priority(
        self, task_info: FileTaskInfo, current_quota_status: dict, task_age_seconds: float = 0
    ) -> int:
        """
        è®¡ç®—æ–‡ä»¶ä»»åŠ¡ä¼˜å…ˆçº§

        Args:
            task_info: æ–‡ä»¶ä»»åŠ¡ä¿¡æ¯
            current_quota_status: å½“å‰é…é¢çŠ¶æ€
            task_age_seconds: ä»»åŠ¡å·²ç­‰å¾…æ—¶é—´

        Returns:
            int: ä¼˜å…ˆçº§åˆ†æ•° (0-9, 0æœ€é«˜)
        """

        # 1. APIé…é¢æ•ˆç‡ - æ¯ä¸ªAPIè°ƒç”¨é¢„æœŸè·å¾—çš„keyæ•°é‡
        key_density = task_info.estimated_key_density
        file_size_kb = task_info.file_size / 1024

        # æ–‡ä»¶è¶Šå°ã€keyå¯†åº¦è¶Šé«˜ï¼Œæ•ˆç‡è¶Šé«˜
        if file_size_kb <= 10:  # å°æ–‡ä»¶
            size_efficiency = 1.0
        elif file_size_kb <= 100:  # ä¸­ç­‰æ–‡ä»¶
            size_efficiency = 0.7
        else:  # å¤§æ–‡ä»¶
            size_efficiency = 0.4

        api_quota_efficiency = key_density * size_efficiency

        # 2. é¢„æœŸæˆåŠŸç‡
        # åŸºäºä»“åº“è´¨é‡å’Œæ–‡ä»¶ç±»å‹
        repo_quality = task_info.repo_popularity_score * 0.6 + task_info.repo_freshness_score * 0.4

        # æ–‡ä»¶ç±»å‹æˆåŠŸç‡
        if task_info.file_path.endswith(".env"):
            file_type_success = 0.9
        elif task_info.file_path.endswith((".config", ".json", ".yaml")):
            file_type_success = 0.8
        elif task_info.file_path.endswith((".js", ".ts", ".py")):
            file_type_success = 0.7
        else:
            file_type_success = 0.5

        expected_success_rate = repo_quality * 0.7 + file_type_success * 0.3

        # 3. ä»“åº“ä»·å€¼
        repo_value = (task_info.repo_popularity_score + task_info.repo_freshness_score) / 2

        # 4. ä»»åŠ¡ç´§æ€¥åº¦ - åŸºäºç­‰å¾…æ—¶é—´å’Œé…é¢çŠ¶æ€
        urgency_base = min(task_age_seconds / 3600, 1.0)  # ç­‰å¾…æ—¶é—´å½±å“

        # é…é¢å……è¶³æ—¶é™ä½ç´§æ€¥åº¦ï¼Œé…é¢ç´§å¼ æ—¶æé«˜ç´§æ€¥åº¦
        github_quota_ratio = current_quota_status.get("github", {}).get("avg_health_score", 0.5)
        if github_quota_ratio > 0.7:
            urgency_multiplier = 0.8  # é…é¢å……è¶³ï¼Œä¸ç€æ€¥
        elif github_quota_ratio < 0.3:
            urgency_multiplier = 1.5  # é…é¢ç´§å¼ ï¼ŒæŠ“ç´§å¤„ç†é«˜ä»·å€¼ä»»åŠ¡
        else:
            urgency_multiplier = 1.0

        task_urgency = urgency_base * urgency_multiplier

        # 5. èµ„æºæˆæœ¬ - æ–‡ä»¶å¤§å°å’Œé¢„æœŸå¤„ç†æ—¶é—´
        processing_time_estimate = max(1, file_size_kb / 100)  # ä¼°ç®—å¤„ç†æ—¶é—´
        resource_cost = 1.0 / processing_time_estimate  # æˆæœ¬è¶Šä½åˆ†æ•°è¶Šé«˜

        # ç»¼åˆè®¡ç®—
        weighted_score = (
            api_quota_efficiency * self.weights["api_quota_efficiency"]
            + expected_success_rate * self.weights["expected_success_rate"]
            + repo_value * self.weights["repo_value"]
            + task_urgency * self.weights["task_urgency"]
            + resource_cost * self.weights["resource_cost"]
        )

        # è½¬æ¢ä¸ºä¼˜å…ˆçº§ç­‰çº§ (0-9)
        if weighted_score >= 0.8:
            return TaskPriority.CRITICAL.value
        if weighted_score >= 0.65:
            return TaskPriority.HIGH.value
        if weighted_score >= 0.4:
            return TaskPriority.MEDIUM.value
        if weighted_score >= 0.2:
            return TaskPriority.LOW.value
        return TaskPriority.BACKGROUND.value

    def calculate_validation_task_priority(
        self, task_info: KeyValidationTaskInfo, current_quota_status: dict, task_age_seconds: float = 0
    ) -> int:
        """
        è®¡ç®—keyéªŒè¯ä»»åŠ¡ä¼˜å…ˆçº§

        Args:
            task_info: KeyéªŒè¯ä»»åŠ¡ä¿¡æ¯
            current_quota_status: å½“å‰é…é¢çŠ¶æ€
            task_age_seconds: ä»»åŠ¡å·²ç­‰å¾…æ—¶é—´

        Returns:
            int: ä¼˜å…ˆçº§åˆ†æ•° (0-9, 0æœ€é«˜)
        """

        # 1. Keyå¯ä¿¡åº¦ - è¿™ä¸ªkeyæœ‰æ•ˆçš„å¯èƒ½æ€§
        key_confidence = task_info.key_confidence_score

        # 2. ä»“åº“ä»·å€¼
        if task_info.repo_stars >= 1000:
            repo_value = 1.0
        elif task_info.repo_stars >= 100:
            repo_value = 0.8
        elif task_info.repo_stars >= 10:
            repo_value = 0.6
        else:
            repo_value = 0.4

        # 3. éªŒè¯ç´§æ€¥åº¦ - åŸºäºGeminié…é¢çŠ¶æ€
        gemini_health = current_quota_status.get("gemini", {}).get("success_rate", 0.8)
        recent_429 = current_quota_status.get("gemini", {}).get("recent_429", False)

        if recent_429:
            urgency_multiplier = 0.5  # æœ€è¿‘æœ‰429ï¼Œé™ä½ä¼˜å…ˆçº§
        elif gemini_health > 0.9:
            urgency_multiplier = 1.2  # éªŒè¯çŠ¶æ€å¾ˆå¥½ï¼Œæé«˜ä¼˜å…ˆçº§
        else:
            urgency_multiplier = 1.0

        urgency = min(task_age_seconds / 1800, 1.0) * urgency_multiplier  # 30åˆ†é’Ÿå†…çº¿æ€§å¢é•¿

        # 4. APIæ•ˆç‡ - é«˜å¯ä¿¡åº¦keyä¼˜å…ˆéªŒè¯ï¼Œé¿å…æµªè´¹é…é¢
        api_efficiency = key_confidence

        # ç»¼åˆè®¡ç®—
        weighted_score = key_confidence * 0.4 + repo_value * 0.3 + urgency * 0.2 + api_efficiency * 0.1

        # è½¬æ¢ä¸ºä¼˜å…ˆçº§ç­‰çº§
        if weighted_score >= 0.8:
            return TaskPriority.CRITICAL.value
        if weighted_score >= 0.6:
            return TaskPriority.HIGH.value
        if weighted_score >= 0.4:
            return TaskPriority.MEDIUM.value
        if weighted_score >= 0.2:
            return TaskPriority.LOW.value
        return TaskPriority.BACKGROUND.value


class QuotaAwarePriorityQueue:
    """APIé…é¢æ„ŸçŸ¥çš„ä¼˜å…ˆçº§é˜Ÿåˆ—"""

    def __init__(self, queue_type: str, max_size: int = 1000):
        self.queue_type = queue_type  # 'github' or 'gemini'
        self.max_size = max_size
        self.queue: list[tuple[int, float, str, Any]] = []  # (priority, timestamp, task_id, task_data)
        self.priority_calculator = PriorityCalculator()

        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            "total_added": 0,
            "total_removed": 0,
            "priority_distribution": dict.fromkeys(range(10), 0),
            "queue_full_rejections": 0,
            "reprioritizations": 0,
        }

        logger.info(f"ğŸ“Š QuotaAwarePriorityQueue initialized for {queue_type}, max_size: {max_size}")

    def add_file_task(
        self, task_id: str, task_info: FileTaskInfo, current_quota_status: dict, task_data: Any = None
    ) -> bool:
        """
        æ·»åŠ æ–‡ä»¶ä»»åŠ¡åˆ°é˜Ÿåˆ—

        Args:
            task_id: ä»»åŠ¡ID
            task_info: æ–‡ä»¶ä»»åŠ¡ä¿¡æ¯
            current_quota_status: å½“å‰é…é¢çŠ¶æ€
            task_data: ä»»åŠ¡æ•°æ®

        Returns:
            bool: æ˜¯å¦æˆåŠŸæ·»åŠ 
        """
        if len(self.queue) >= self.max_size:
            self.stats["queue_full_rejections"] += 1
            logger.warning(f"ğŸ“¦ {self.queue_type} queue full, rejecting task {task_id}")
            return False

        # è®¡ç®—ä¼˜å…ˆçº§
        priority = self.priority_calculator.calculate_file_task_priority(task_info, current_quota_status)

        # æ·»åŠ åˆ°é˜Ÿåˆ—
        timestamp = time.time()
        heapq.heappush(self.queue, (priority, timestamp, task_id, task_data))

        # æ›´æ–°ç»Ÿè®¡
        self.stats["total_added"] += 1
        self.stats["priority_distribution"][priority] += 1

        logger.debug(f"ğŸ“¥ Added {self.queue_type} task {task_id} with priority {priority}")
        return True

    def add_validation_task(
        self, task_id: str, task_info: KeyValidationTaskInfo, current_quota_status: dict, task_data: Any = None
    ) -> bool:
        """
        æ·»åŠ éªŒè¯ä»»åŠ¡åˆ°é˜Ÿåˆ—

        Args:
            task_id: ä»»åŠ¡ID
            task_info: KeyéªŒè¯ä»»åŠ¡ä¿¡æ¯
            current_quota_status: å½“å‰é…é¢çŠ¶æ€
            task_data: ä»»åŠ¡æ•°æ®

        Returns:
            bool: æ˜¯å¦æˆåŠŸæ·»åŠ 
        """
        if len(self.queue) >= self.max_size:
            self.stats["queue_full_rejections"] += 1
            logger.warning(f"ğŸ“¦ {self.queue_type} queue full, rejecting validation task {task_id}")
            return False

        # è®¡ç®—ä¼˜å…ˆçº§
        priority = self.priority_calculator.calculate_validation_task_priority(task_info, current_quota_status)

        # æ·»åŠ åˆ°é˜Ÿåˆ—
        timestamp = time.time()
        heapq.heappush(self.queue, (priority, timestamp, task_id, task_data))

        # æ›´æ–°ç»Ÿè®¡
        self.stats["total_added"] += 1
        self.stats["priority_distribution"][priority] += 1

        logger.debug(f"ğŸ“¥ Added validation task {task_id} with priority {priority}")
        return True

    def get_next_task(self) -> tuple[str, Any] | None:
        """
        è·å–ä¸‹ä¸€ä¸ªä»»åŠ¡

        Returns:
            Optional[Tuple[str, Any]]: (task_id, task_data) æˆ– None
        """
        if not self.queue:
            return None

        priority, timestamp, task_id, task_data = heapq.heappop(self.queue)

        # æ›´æ–°ç»Ÿè®¡
        self.stats["total_removed"] += 1
        self.stats["priority_distribution"][priority] -= 1

        logger.debug(f"ğŸ“¤ Retrieved {self.queue_type} task {task_id} with priority {priority}")
        return task_id, task_data

    def peek_next_task(self) -> tuple[int, str] | None:
        """
        æŸ¥çœ‹ä¸‹ä¸€ä¸ªä»»åŠ¡ä½†ä¸ç§»é™¤

        Returns:
            Optional[Tuple[int, str]]: (priority, task_id) æˆ– None
        """
        if not self.queue:
            return None

        priority, timestamp, task_id, task_data = self.queue[0]
        return priority, task_id

    def reprioritize_tasks(self, current_quota_status: dict):
        """
        é‡æ–°è®¡ç®—æ‰€æœ‰ä»»åŠ¡çš„ä¼˜å…ˆçº§

        Args:
            current_quota_status: å½“å‰é…é¢çŠ¶æ€
        """
        if not self.queue:
            return

        # æå–æ‰€æœ‰ä»»åŠ¡
        old_tasks = []
        while self.queue:
            priority, timestamp, task_id, task_data = heapq.heappop(self.queue)
            old_tasks.append((timestamp, task_id, task_data))

        # é‡æ–°è®¡ç®—ä¼˜å…ˆçº§å¹¶æ·»åŠ å›é˜Ÿåˆ—
        current_time = time.time()
        for timestamp, task_id, task_data in old_tasks:
            task_age = current_time - timestamp

            # è¿™é‡Œéœ€è¦æ ¹æ®task_dataçš„ç±»å‹æ¥é‡æ–°è®¡ç®—ä¼˜å…ˆçº§
            # ç®€åŒ–å®ç°ï¼šä¿æŒåŸæœ‰ä¼˜å…ˆçº§ä½†æ·»åŠ å¹´é¾„åŠ æˆ
            age_bonus = min(int(task_age / 600), 2)  # æ¯10åˆ†é’Ÿé™ä½1ä¸ªä¼˜å…ˆçº§ç­‰çº§ï¼Œæœ€å¤š2çº§
            new_priority = max(0, priority - age_bonus)

            heapq.heappush(self.queue, (new_priority, timestamp, task_id, task_data))

        self.stats["reprioritizations"] += 1
        logger.info(f"ğŸ”„ Reprioritized {len(old_tasks)} tasks in {self.queue_type} queue")

    def clear_low_priority_tasks(self, min_priority: int = 7) -> int:
        """
        æ¸…ç†ä½ä¼˜å…ˆçº§ä»»åŠ¡

        Args:
            min_priority: æœ€ä½ä¿ç•™ä¼˜å…ˆçº§

        Returns:
            int: æ¸…ç†çš„ä»»åŠ¡æ•°é‡
        """
        if not self.queue:
            return 0

        # æå–æ‰€æœ‰ä»»åŠ¡
        all_tasks = []
        while self.queue:
            all_tasks.append(heapq.heappop(self.queue))

        # è¿‡æ»¤é«˜ä¼˜å…ˆçº§ä»»åŠ¡
        kept_tasks = []
        removed_count = 0

        for priority, timestamp, task_id, task_data in all_tasks:
            if priority < min_priority:  # ä¿ç•™é«˜ä¼˜å…ˆçº§ä»»åŠ¡ (æ•°å­—è¶Šå°ä¼˜å…ˆçº§è¶Šé«˜)
                kept_tasks.append((priority, timestamp, task_id, task_data))
            else:
                removed_count += 1
                # æ›´æ–°ç»Ÿè®¡
                self.stats["priority_distribution"][priority] -= 1

        # é‡æ–°æ„å»ºé˜Ÿåˆ—
        for task in kept_tasks:
            heapq.heappush(self.queue, task)

        if removed_count > 0:
            logger.info(f"ğŸ§¹ Cleared {removed_count} low priority tasks from {self.queue_type} queue")

        return removed_count

    def get_queue_stats(self) -> dict:
        """è·å–é˜Ÿåˆ—ç»Ÿè®¡ä¿¡æ¯"""
        priority_counts = {
            f"priority_{i}": count for i, count in self.stats["priority_distribution"].items() if count > 0
        }

        return {
            "queue_type": self.queue_type,
            "current_size": len(self.queue),
            "max_size": self.max_size,
            "total_added": self.stats["total_added"],
            "total_removed": self.stats["total_removed"],
            "queue_full_rejections": self.stats["queue_full_rejections"],
            "reprioritizations": self.stats["reprioritizations"],
            "priority_distribution": priority_counts,
        }
